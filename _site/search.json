[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Shiny Assisted Solar Ages\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2025\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\n\n\n\n\n\n\nCharacter to Date conversion using lazy queries\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2025\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\n\n\n\n\n\n\nAlternative Hover Text In Custom Function with plotly\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\n\n\n\n\n\n\nAdvent Calendar Ratings Dashboard\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2025\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\n\n\n\n\n\n\nRolling 5-year Sum Label Using slider\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2024\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\n\n\n\n\n\n\nNBA Final 2024 Process Mining\n\n\n\n\n\nThe NBA final has concluded and I would like to play with process mining packages in bupaverse, let‚Äôs marry them.\n\n\n\n\n\nSep 11, 2024\n\n\nAuthor: Kurtis Smith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Grand! You made it, greetings üëãüèΩ\nI‚Äôm a data scientist.\nCoding prerequisites include a big screen to not burden my failing eyes too much. A challenge to break the monotony. One cup of black coffee, hold the sugar and milk.\nOften background music without lyrics otherwise I‚Äôll just sing along e.g.¬†Chillhop or DnB. 1-3 chinwags to decompress. A healthy portion of food with all the trimmings.\nBeyond coding: I lay my hat in London, UK, and share the utilities with my son and fianc√©. I‚Äôm a fan of both basketball üèÄ and ‚öΩ football. Love a good read, mainly fantasy. Favourite books are The Gentlemen Bastard & Mistborn Series, follow me on Storygraph, username kurtisasha.\nI like to game. I fell hard for Final Fantasy 8 back in the 90‚Äôs and if limited to one dish for the rest of my life, it‚Äôll be üçï pizza."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html",
    "href": "posts/2024-09-11-nba-final-flow/index.html",
    "title": "NBA Final 2024 Process Mining",
    "section": "",
    "text": "Inspired by Kr√∂ckel and Bodendorf (2020), this analysis will use R to explore process mining on a subject I am fond of - basketball. I have played basketball all my life, although my failing left knee means I play infrequently in my older age.\nI will be analysing game 5 of the 2024 NBA final between Donƒçiƒá, Dallas Mavericks and Tatum, Boston Celtics. Well done Celtics üçÄ, who last won a championship 16 years ago. I will avoid findings which could just as easily be found in a games summary statistics and focus on what unique insights process mining provides. Let us start with the data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(bupaverse)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(DT)\nlibrary(psmineR)\n\n# Global settings\nknitr::opts_chunk$set(\n    echo = TRUE,\n    message = FALSE,\n    warning = FALSE\n)\ntheme_set(theme_minimal(base_family = 'serif'))\n\n# Get data\nnba_2024_g5_pm_data &lt;- read_csv('./input/nba-final-2024-game-5.csv', col_names = TRUE) %&gt;% \n mutate(\n  resource_id = case_when(\n   resource_id == 'Luka Doncic' ~ 'Luka_Donƒçiƒá', \n   resource_id == 'Kristaps Porzingis' ~ 'Kristaps_Porzi≈Üƒ£is',\n   TRUE ~ resource_id)\n  )"
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#project-introduction",
    "href": "posts/2024-09-11-nba-final-flow/index.html#project-introduction",
    "title": "NBA Final 2024 Process Mining",
    "section": "",
    "text": "Inspired by Kr√∂ckel and Bodendorf (2020), this analysis will use R to explore process mining on a subject I am fond of - basketball. I have played basketball all my life, although my failing left knee means I play infrequently in my older age.\nI will be analysing game 5 of the 2024 NBA final between Donƒçiƒá, Dallas Mavericks and Tatum, Boston Celtics. Well done Celtics üçÄ, who last won a championship 16 years ago. I will avoid findings which could just as easily be found in a games summary statistics and focus on what unique insights process mining provides. Let us start with the data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(bupaverse)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(DT)\nlibrary(psmineR)\n\n# Global settings\nknitr::opts_chunk$set(\n    echo = TRUE,\n    message = FALSE,\n    warning = FALSE\n)\ntheme_set(theme_minimal(base_family = 'serif'))\n\n# Get data\nnba_2024_g5_pm_data &lt;- read_csv('./input/nba-final-2024-game-5.csv', col_names = TRUE) %&gt;% \n mutate(\n  resource_id = case_when(\n   resource_id == 'Luka Doncic' ~ 'Luka_Donƒçiƒá', \n   resource_id == 'Kristaps Porzingis' ~ 'Kristaps_Porzi≈Üƒ£is',\n   TRUE ~ resource_id)\n  )"
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#data-treatment",
    "href": "posts/2024-09-11-nba-final-flow/index.html#data-treatment",
    "title": "NBA Final 2024 Process Mining",
    "section": "Data Treatment",
    "text": "Data Treatment\nThe data collation was a manual effort, a labour of love. After watching game 5 of the 2024 NBA finals I painstakingly noted down each activity along with the timestamp.\nTo add assurance to this data set I checked each activity available on @nba.com/play-by-play matched on timestamp and cross checked the summary player stats against @nba.com/box-score.\nA few self imposed rules during data creation:\n\nTo define the process under analysis, one end to end run or ‚Äòcase‚Äô ends with a shot\nFor free throws the case ends at the last free throw attempt\nUnless specified from the nba website I have timestamped at the beginning of each activity\n\nData is available on Kaggle or Github"
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#create-eventlog",
    "href": "posts/2024-09-11-nba-final-flow/index.html#create-eventlog",
    "title": "NBA Final 2024 Process Mining",
    "section": "Create Eventlog",
    "text": "Create Eventlog\nAn eventlog in process mining is a structured collection of recorded events that represent the execution of activities usually within a business process, in this context, an NBA game.\nIt typically contains information such as the event type, timestamp, case identifier, and other relevant attributes, serving as the primary input for process mining techniques to discover, monitor, and improve actual processes.\nOnce an event log object has been created, the object can be used across multiple analyses.\n\nnba_final_g5_eventlog &lt;-  nba_2024_g5_pm_data %&gt;% \n mutate(lifecycle_id = 'complete', \n        timestamp = ymd_hms(paste0('20240617 ', timestamp))) %&gt;% \n eventlog(case_id = 'case_id', \n          activity_id = 'activity_id', \n          activity_instance_id = 'seq', \n          lifecycle_id = 'lifecycle_id', \n          timestamp = 'timestamp', \n          resource_id = 'resource_id', \n          order = 'seq', \n          validate = TRUE)"
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#analyses",
    "href": "posts/2024-09-11-nba-final-flow/index.html#analyses",
    "title": "NBA Final 2024 Process Mining",
    "section": "Analyses",
    "text": "Analyses\n\nControl-Flow\nControl flow in process mining refers to the sequence and decision points of activities within a process. This perspective explores the flow of the game.\n\nTraces\nTraces are the distinct processes of an eventlog, in this context, a play which starts at the beginning of a quarter of post shot attempt until another shot attempt.\n\nCoverage\nReviewing the trace coverage relative to cases let us us see if the same plays are used throughout or if plays are variable. The plots display relative frequencies above 0.02 to remove the plot tail and make for better viewing.\n\nlog_trace &lt;- nba_final_g5_eventlog %&gt;%\n trace_coverage('trace') %&gt;%\n filter(relative &gt; 0.02) %&gt;%\n plot() +\n theme(legend.position = 'top') +\n scale_fill_viridis('Relative Frequency',\n                    option = 'D',\n                    direction = -1) +\n scale_y_continuous(limits = c(0, 0.45), \n                    breaks = seq(0, 0.45, 0.05)) +\n scale_x_continuous(breaks = seq(0, 1, 0.2)) +\n labs(title = 'Play variance') +\n ylab('')\n\n\nunited_log_trace &lt;- nba_final_g5_eventlog %&gt;%\n act_unite(\n  pass = c(\n   'pass-to-assist',\n   'pass',\n   'pass-turnover',\n   'pass-to-start-quarter'\n  ),\n  dribble = c('dribble', 'dribble-turnover'),\n  rebound = c('defensive-rebound', 'offensive-rebound'),\n  shot = c('shot-miss', 'shot-make')\n ) %&gt;%\n trace_coverage('trace') %&gt;%\n filter(relative &gt; 0.02) %&gt;%\n plot() +\n theme(legend.position = 'top') +\n scale_fill_viridis('Relative Frequency',\n                    option = 'D',\n                    direction = -1) +\n scale_y_continuous(limits = c(0, 0.45), \n                    breaks = seq(0, 0.45, 0.05)) +\n scale_x_continuous(breaks = seq(0, 1, 0.2)) +\n labs(title = 'Play variance with unified activities') +\n ylab('')\n\n (log_trace + united_log_trace) +\n plot_layout(axes = 'collect')\n\n\n\n\n\n\n\n\nAs the left plot displays a max relative frequency of 0.03, the plays of this game varied considerably. Even when grouping activities e.g.¬†dribble and dribble-turnover both set as dribble, a max relative frequency of 0.06 as shown in the right plot.\nWith more detailed data around off the ball movements and data on many more games, perhaps you could use trace coverage analysis to: - Indicate if systematic plays are used, shown by an increase in the relative frequency - Compare across teams and games to see if this metric shares patterns with tradition metrics i.e.¬†win/loss, plus/minus etc\n\n\nTeam Trace Length\nReviewing the trace sizes for each team i.e.¬†The number of activities used until a shot attempt.\n\nshot_made_plot &lt;- nba_final_g5_eventlog %&gt;%\n filter_activity_presence('shot-make') %&gt;%\n group_by(teams_play) %&gt;%\n trace_length('log') %&gt;%\n plot() +\n theme(strip.background = element_rect(fill = viridis::viridis(1, direction = 1))) +\n geom_jitter(alpha = 0.7, size = 2) +\n geom_boxplot(fill = viridis::viridis(1, alpha = 0.6, direction = -1), \n              colour = '#000000') +\n stat_boxplot(geom = 'errorbar', linetype = 'dashed', width = 0.1) +\n scale_y_continuous(limits = c(0, 18)) +\n labs(title = 'Teams Traces by Shot Made')\n\nshot_miss_plot &lt;- nba_final_g5_eventlog %&gt;%\n filter_activity_presence('shot-miss') %&gt;%\n group_by(teams_play) %&gt;%\n trace_length('log') %&gt;%\n plot() +\n theme(strip.background = element_rect(fill = viridis::viridis(1, direction = 1))) +\n geom_jitter(alpha = 0.7, size = 2) +\n geom_boxplot(fill = viridis::viridis(1, alpha = 0.6, direction = -1), \n              colour = '#000000') +\n stat_boxplot(geom = 'errorbar', linetype = 'dashed', width = 0.1) +\n scale_y_continuous(limits = c(0, 18)) +\n labs(title = 'Teams Traces by Shot Miss')\n\n(shot_made_plot + shot_miss_plot) +\n plot_layout(axes = 'collect')\n\n\n\n\n\n\n\n\nAll look similar except Dallas for plays which end in a miss. Lets look into this further by spliting Dallas traces by quarter.\n\nnba_final_g5_eventlog %&gt;%\n filter(teams_play == 'Dallas Mavericks') %&gt;% \n filter_activity_presence('shot-miss') %&gt;%\n group_by(quarter) %&gt;% \n trace_length('log') %&gt;%\n plot() +\n theme(strip.background = element_rect(fill = viridis::viridis(1, direction = 1))) +\n geom_jitter(alpha = 0.7, size = 2) +\n geom_boxplot(fill = viridis::viridis(1, alpha = 0.6, direction = -1), \n              colour = '#000000') +\n stat_boxplot(geom = 'errorbar', linetype = 'dashed', width = 0.1) +\n scale_y_continuous(limits = c(0, 18)) +\n labs(title = 'Dallas Traces by Shot Miss & Quarter')\n\n\n\n\n\n\n\n\nThe 4th quarter has higher average and max trace lengths at a time when they needed to make a push.\nThere could be multiple reasons as to why, perhaps Boston played brilliant defence forcing Dallas to pass more in order to shift the defence and make space.\nRegardless this ran down the clock limiting the number of available opportunities to reduce the deficit.\nLet us view that 4th quarter outlier process to see why.\n\nlongest_trace &lt;- nba_final_g5_eventlog %&gt;%\n filter(teams_play == 'Dallas Mavericks') %&gt;%\n filter_activity_presence('shot-miss') %&gt;%\n filter_trace_length(percentage = 0.01) %&gt;% \n count(case_id, sort = TRUE) %&gt;% \n head(1) %&gt;% \n pull(case_id)\n\nnba_final_g5_eventlog %&gt;%\n filter_case(cases = longest_trace) %&gt;% \n as.data.frame() %&gt;% \n select(case_id, seq, activity_id, player_team, teams_play) %&gt;% \n datatable(class = c('compact', 'hover', 'row-border'), \n           rownames = FALSE, \n           options = list(dom = 't'))\n\n\n\n\n\nThis outlier is explained by how a play is defined by a shot attempt. Boston held position at the onset but turned over possession to Dallas, shortly after Dallas made a shot attempt.\n\n\n\nPrecedences\nReviewing the activity process matrix allows for investigation into antecedent and consequential activities. Each activity row will sum to 100%.\n\nnba_final_g5_eventlog %&gt;%\n process_matrix(type = frequency('relative-antecedent')) %&gt;% \n plot() +\n theme(legend.position = 'top') +\n scale_fill_viridis(option = 'D', name = 'Relative Antecedence', direction = -1)\n\n\n\n\n\n\n\n\nAcross the game ~70% of all passes were followed by a dribble whilst ~20% of the time it was followed by another pass. Additional data and further analysis could shed light on, if these figures typified finals or playing styles of NBA teams.\n~55% of the time a defensive rebound was followed by a dribble, and ~38% a pass. Your taught to grab the rebound and look for the outlet (at least in the United Kingdom) yet in this game the dribble was preferred. If you had player positions you may look to investigate if a lack of outlet options was the reason or perhaps the rebound was caught closer to the 3pt line than under the rim so it made more sense to move the ball up the court for a fast break.\n\n\n\nPerformance\nPerformance analysis typically involves metrics such as time to complete activity, time in between each activity, and total time of process to understand the factors affecting process performance.\n\nThroughput Time\nThis analysis is limited by the time stamps collected. If I had start and end times of each activity, more granular analysis could be performed. As it stands only total time across process is available, also know as throughput time.\n\nthroughput_make_plot &lt;- nba_final_g5_eventlog %&gt;% \n  group_by(teams_play) %&gt;%\n  filter_activity_presence('shot-make', method = 'none') %&gt;% \n  throughput_time('log', units = 'secs') %&gt;%\n  plot() + \n  theme(strip.background = element_rect(fill = viridis::viridis(1, direction = 1))) +\n  geom_jitter(alpha = 0.7, size = 2, ) +\n  geom_boxplot(fill = viridis::viridis(1, alpha = 0.6, direction = -1), \n               colour = '#000000') +\n  stat_boxplot(geom = 'errorbar', linetype = 'dashed', width = 0.1) +\n  scale_y_continuous(limits = c(-5, 45)) +\n  labs(title = 'Teams Traces by Shot Make')\n\nthroughput_miss_plot &lt;- nba_final_g5_eventlog %&gt;% \n  group_by(teams_play) %&gt;%\n  filter_activity_presence('shot-miss', method = 'none') %&gt;% \n  throughput_time('log', units = 'secs') %&gt;%\n  plot() +\n  theme(strip.background = element_rect(fill = viridis::viridis(1, direction = 1))) +\n  geom_jitter(alpha = 0.7, size = 2) +\n  geom_boxplot(fill = viridis::viridis(1, alpha = 0.6, direction = -1), \n               colour = '#000000') +\n  stat_boxplot(geom = 'errorbar', linetype = 'dashed', width = 0.1) +\n  scale_y_continuous(limits = c(-5, 45)) +\n  labs(title = 'Teams Traces by Shot Miss')\n\n (throughput_make_plot + throughput_miss_plot) +\n  plot_layout(axes = 'collect')\n\n\n\n\n\n\n\n\n\nBostons interquartile range is wider than Dallas‚Äôs, 50% of Bostons plays are more varied in time than 50% of Dallas‚Äô.\nFor shots made by Dallas the interquartile range is half that of Boston. 50% of Dallas‚Äôs plays were quick, perhaps rushed due to score deficit.\n\n\n\nProcess Map\nProcess mining isn‚Äôt complete without a process map. Split by team plays, you could dig for many insights looking across both maps.\n\nBoston Celtics\n\nnba_final_g5_eventlog %&gt;%\n filter(teams_play == 'Boston Celtics') %&gt;% \n process_map(\n  type_nodes = frequency('absolute'),\n  type_edges = performance(mean, 'secs'),\n  rankdir = 'TB'\n )\n\n\n\n\n\n\n\nDallas Mavericks\n\nnba_final_g5_eventlog %&gt;%\n filter(teams_play == 'Dallas Mavericks') %&gt;% \n process_map(\n  type_nodes = frequency('absolute'),\n  type_edges = performance(mean, 'secs'),\n  rankdir = 'TB'\n )\n\n\n\n\n\nA few noteworthy insights:\n\nBoston was more industrious than Dallas. Having completed more passes, dribbles, rebounds, blocks etc\nBoston was 1 second quicker on average to make a shot attempt after a defensive rebound.\nBoth teams passed the ball with similar average times: Boston with 1.2 seconds and Dallas 1.51 seconds, for passes not leading to an assist. Boston 2.31 seconds and Dallas 2.5 seconds for passes leading to an assist. In both cases Boston were on average quicker and sharper in moving the ball.\n\n\n\n\nSpectra\nReferenced in @bupaverse_spectrum, Denisov, Fahland, and Aalst (2018) provides another avenue to analyse performance. What the authors term ‚Äòperformance spectra‚Äô defined as ‚ÄòThe Performance Spectrum is a fully detailed data structure and visualization of all cases over all segments over time‚Äô provides a taxonomy of performance patterns.\n\nnba_final_g5_eventlog %&gt;%\n  ps_detailed(segment_coverage = 0.15, classification = 'teams_play') +\n  scale_colour_viridis_d(name = 'Team Plays') +\n  theme(\n   strip.background = element_rect(fill = viridis::viridis(1, direction = 1)),\n   strip.text = element_text(colour = '#ffffff'),\n   legend.position = \"top\"\n  )\n\n\n\n\n\n\n\n\nI have opted for 15% coverage of plays (or cases) as most would be sparse and beyond evaluating. In line with the taxonomy, this event has generally 2 elementary patterns:\n\nFor dribble to pass and vice versa: The pattern follows a single segment with globally occurring instances, with regular repetitions, and a continuous workload across the course of the event, the full 45 mins.\nThe rest of the pairwise segments had a similar taxonomy with a sparse workload.\n\nInteresting analysis when applied to administrative data as is the case for Denisov, Fahland, and Aalst (2018). However offers little when applied to this dataset. If this dataset included off the ball movement and/or multiple games, perhaps analysis of performance spectra would be more fruitful.\n\n\n\nOrganisational\nOrganisational analysis refers to the examination of the social and organisational aspects of a business process, such as the resources, responsibilities, and interactions of the individuals involved.\n\nResource Industry\nLooking at the top 10 industrious players, the players with higher frequency of activities. You would expect to see your star players at the top.\n\nnba_final_g5_eventlog %&gt;% \n resource_frequency(level = 'resource') %&gt;%\n head(10) %&gt;%\n plot() +\n theme(legend.position = 'none') +\n scale_fill_viridis('Frequency',\n                    option = 'D',\n                    direction = -1) +\n labs(title = 'Player Industriousness') +\n xlab('')\n\n\n\n\n\n\n\n\nAs you would expect, Tatum, Donƒçiƒá, and Brown rank in the top 3. Irving was not as involved as Dallas would have liked. Boston hold 4 of the 5 top spots, they certainly brought the game to Dallas.\n\n\nSpecialisation\n\nnba_final_g5_eventlog %&gt;% \n group_by(player_team) %&gt;% \n resource_frequency(level = 'resource-activity') %&gt;%\n filter(!resource_id %in% c('Boston Celtics', 'Dallas Mavericks'), \n        absolute &gt; 1) %&gt;%\n plot() + \n theme(legend.position = 'top') +\n scale_fill_viridis(option = 'D', name = 'Relative Antecedence', direction = -1) +\n ylab('')\n\n\n\n\n\n\n\n\nOne game doesn‚Äôt make a specialist but for the purposes of exploration let us see who was a one-game specialist, who excels at a type of activity. Note, I have removed any activities that happened only once to reduce dimensions and make it easy viewing.\nA few noteworthy insights\n\nThere are more Dallas players than Boston, the specialisation of activities was spread wider for Dallas.\nDonƒçiƒá held the pass master title for Dallas and was certainly his teams passing specialist whilst Boston shared that specialisation across 4 players.\nDonƒçiƒá specialised in defensive rebounds for his team as well as passing, were as Boston shared this responsibility across 4 players.\n\nAlthough there were more Dallas specialists, Donƒçiƒá was the main specialist in passing, and defensive rebounding comparative to his team whilst Boston often had several specialists in any given activity. This would have hindered Dallas when Donƒçiƒá was subbed and benefited Boston during bench rotation.\n\n\nHandover work\nHandover analysis explores how work is handed off from one person or step to the next.\nIn the following resource maps, I will be looking at the 20% most frequent plays or traces.\n\nBoston Celtics\n\nnba_final_g5_eventlog %&gt;%\n mutate(resource_id = if_else(\n  resource_id == 'Jaylen Brown', 'J. Brown', resource_id)) %&gt;%\n filter(teams_play == 'Boston Celtics') %&gt;%\n filter_trace_frequency(percentage = 0.2) %&gt;%\n resource_map()\n\n\n\n\n\nJayson Tatum was passed to most (9) by Derrick White but only by 1 more pass. Followed by Jrue Holiday passing to Derrick White (8). Handover work is generally even across the most industrious players in Boston\n\n\nDallas Mavericks\n\nnba_final_g5_eventlog %&gt;%\n filter(teams_play == 'Dallas Mavericks') %&gt;% \n filter_trace_frequency(percentage = 0.2) %&gt;% \n resource_map()\n\n\n\n\n\nComparative to Boston, Dallas rotated the basketball less. The highest handover score between players being 3.\nFor at least 20% of the most frequent plays, Boston moved the ball more, this is almost always a good sign in basketball, it often equates to: - Improved player engagement - Players better attuned to game tempo - Players warm up quicker, essential for a sport which has constant substitutions"
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#conclusion",
    "href": "posts/2024-09-11-nba-final-flow/index.html#conclusion",
    "title": "NBA Final 2024 Process Mining",
    "section": "Conclusion",
    "text": "Conclusion\n\nGame\nGame 5 of the NBA 2024 finals had high variance in plays, with Boston winning the game. Boston was more industrious, their star players were more effective, were quicker at getting the shot up after defensive rebounds, moved the ball quicker, and had better rotation of the ball than Dallas.\nDallas really were never in the game, being thwarted whenever they mounted an attack. Dallas were unable to get Irving into the game, relied too much on Donƒçiƒá, and were second best.\n\n\nMethod\nProcess mining applied to basketball has shown clear and easily digestible insights into the behaviours of both teams. That being said there is no open dataset well fitted towards this analysis for public use. I had to heavily enrich traditional play-by-play data. This time resource intensive approach, albeit as a personal project, means I will unlikely gather more data despite the analysis benefitting from it.\nFurther analysis into evasion sports like basketabll could look into including off the ball activity for process mining analysis, in this vein, perhaps individual sports would prove easier requiring less data to generate insight. Either way, the automating of data collection specific and open for the purpose of process mining would spearhead this type of analysis.\nSpecific to this case, having included, as an activity, when players don‚Äôt move with the ball. This would have been interesting to delve into. I suspect you would see the time Celtics held the ball increase in quarter 4 as they attempt to run the clock."
  },
  {
    "objectID": "posts/2024-09-11-nba-final-flow/index.html#acknowledgements",
    "href": "posts/2024-09-11-nba-final-flow/index.html#acknowledgements",
    "title": "NBA Final 2024 Process Mining",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nr-bloggers.com for the reach, platform, and content\nPackages and package maintainer(s):\n\ntidyverse | Hadley Wickham\nbupaverse | Gert Janssenswillen\npatchwork | Thomas Lin Pedersen\nviridis | Simon Garnier\nDT | Joe Cheng\npsmineR | Gert Janssenswillen"
  },
  {
    "objectID": "posts/2025-05-27-shiny-solar-ages/index.html",
    "href": "posts/2025-05-27-shiny-solar-ages/index.html",
    "title": "Shiny Assisted Solar Ages",
    "section": "",
    "text": "Inspired by my son‚Äôs love for everything solar system and my wanting to play with Shiny Assistant. I‚Äôve built an app that takes your date of birth and displays your age for each of the major planets in our solar system."
  },
  {
    "objectID": "posts/2025-05-27-shiny-solar-ages/index.html#project-introduction",
    "href": "posts/2025-05-27-shiny-solar-ages/index.html#project-introduction",
    "title": "Shiny Assisted Solar Ages",
    "section": "",
    "text": "Inspired by my son‚Äôs love for everything solar system and my wanting to play with Shiny Assistant. I‚Äôve built an app that takes your date of birth and displays your age for each of the major planets in our solar system."
  },
  {
    "objectID": "posts/2025-05-27-shiny-solar-ages/index.html#how-to-use",
    "href": "posts/2025-05-27-shiny-solar-ages/index.html#how-to-use",
    "title": "Shiny Assisted Solar Ages",
    "section": "How to Use",
    "text": "How to Use\nUpon launching the app, you‚Äôll see all the controls on the left hand side. Add your date of birth to automatically display your solar ages.\nThere‚Äôs also a toggle to switch to days calculation mode which requires a little explanation.\n\nCalculation Mode\nYear: Gives your Earth age based on a planets orbit.\nDay: Gives your Earth age based on a planets rotation.\nExamples of how the calculation modes work using someone born 27th May 2005.\n\n# Use age is converted to Earth days\nage_difference_in_earth_days &lt;- Sys.Date() -  ymd(\"2005-05-27\")\n\n# The Year calculation divides and floors by the number of Earth days of \n# a planet.\n# Let's use Jupiter which orbits around the Sun every ~4331 Earth days.\n\njupiter_age_year_calc &lt;- floor(age_difference_in_earth_days / 4331.984) |&gt;  \n as.numeric()\n\n# Jupiter age of 20 year old by years calculation\njupiter_age_year_calc\n\n[1] 1\n\n# The Days calculation converts your days Earth age to a planets equivalent. \n# Then divides and floors by an Earth year.\n# Let's use Jupiter which rotates around it's axis every ~9.8 Earth hours\n\nage_difference_in_jupiter_days &lt;- age_difference_in_earth_days / (9.8/24)\n\njupiter_age_days_calc &lt;- floor(age_difference_in_jupiter_days / 365.26) |&gt;  \n as.numeric()\n\n# Jupiter age of 20 year old by days calculation\njupiter_age_days_calc\n\n[1] 49\n\n\nVenus inspired the days-based calculation with it‚Äôs day longer than it‚Äôs year. Still wrapping my head around that."
  },
  {
    "objectID": "posts/2025-05-27-shiny-solar-ages/index.html#dashboard",
    "href": "posts/2025-05-27-shiny-solar-ages/index.html#dashboard",
    "title": "Shiny Assisted Solar Ages",
    "section": "Dashboard",
    "text": "Dashboard\nWell here it is, the Solar System Age Converter.\nThe app was the result of a 2 hour Shiny Assistant assisted play around, a feat I would have spent quadruple the time on. I am a fan of Shiny Assistant but I have notes:\n\nFunctions were sometimes implemented in code without calling the library.\nIt got stuck on the trickier css elements, in my case shadow-root constructed stylesheets.\nI wish a button was introduced to take me to the editor rather than typing ‚ÄúOpen the editor‚Äù.\nI could not clear the console.\nI could use control + f but couldn‚Äôt close.\n\nIt is probable I missed a bunch of functionality in my speed run and I‚Äôll aim to read around, see how others have fared."
  },
  {
    "objectID": "posts/2025-05-27-shiny-solar-ages/index.html#acknowledgements",
    "href": "posts/2025-05-27-shiny-solar-ages/index.html#acknowledgements",
    "title": "Shiny Assisted Solar Ages",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWinston Chang for Shiny Assistant.\nRoyal Museums Greenwich for solar system information.\nr-bloggers.com for the reach, platform, and content\nPackages and package maintainer(s):\n\nlubridate | Vitalie Spinu"
  },
  {
    "objectID": "posts/2025-02-06-plotly-hover-var/index.html",
    "href": "posts/2025-02-06-plotly-hover-var/index.html",
    "title": "Alternative Hover Text In Custom Function with plotly",
    "section": "",
    "text": "How to add alternative text when hovering over a value using plotly for R.\nA few considerations I had to navigate:\n\nplotly behaves well when referencing columns already assigned in one of it‚Äôs arguments, for this problem, the variable in question was in the assigned data but not assigned to any argument. In the example below, this would be the ‚Äúalt_text‚Äù column\nThe alternative text was to be passed into a custom function\nI found a workaround (Thanks DJack from Stack Overflow) which subsets data using $ but I needed to be able to pass any column through a custom function\n\nLet‚Äôs begin with creating test data.\n\n# Load packages\nlibrary(plotly)\nlibrary(rlang)\n\n# Create data\ndf &lt;- data.frame(\n x = 1,\n y = 1,\n text = \"text\",\n alt_text = \"alt_text\"\n)"
  },
  {
    "objectID": "posts/2025-02-06-plotly-hover-var/index.html#problem",
    "href": "posts/2025-02-06-plotly-hover-var/index.html#problem",
    "title": "Alternative Hover Text In Custom Function with plotly",
    "section": "",
    "text": "How to add alternative text when hovering over a value using plotly for R.\nA few considerations I had to navigate:\n\nplotly behaves well when referencing columns already assigned in one of it‚Äôs arguments, for this problem, the variable in question was in the assigned data but not assigned to any argument. In the example below, this would be the ‚Äúalt_text‚Äù column\nThe alternative text was to be passed into a custom function\nI found a workaround (Thanks DJack from Stack Overflow) which subsets data using $ but I needed to be able to pass any column through a custom function\n\nLet‚Äôs begin with creating test data.\n\n# Load packages\nlibrary(plotly)\nlibrary(rlang)\n\n# Create data\ndf &lt;- data.frame(\n x = 1,\n y = 1,\n text = \"text\",\n alt_text = \"alt_text\"\n)"
  },
  {
    "objectID": "posts/2025-02-06-plotly-hover-var/index.html#solution",
    "href": "posts/2025-02-06-plotly-hover-var/index.html#solution",
    "title": "Alternative Hover Text In Custom Function with plotly",
    "section": "Solution",
    "text": "Solution\nThis create_plot() function demonstrates how referencing a column against an argument, allows easy access for the hovertemplate argument to be assigned one of those referenced columns. In this example - text.\n\ncreate_plot &lt;- function(df, text){\n \n text &lt;- enquo(text)\n\n  plot_ly(\n  data = df, \n  x = ~x, \n  y = ~y, \n  width = 300, \n  height = 300,\n  type = \"scatter\",\n  mode = \"text+marker\",\n  text = text,\n  # not necessary but demonstrates code differences\n  hovertemplate = text,\n  textfont = list(size = 50, color = \"#b44046\"))}\n\nThis create_plot_alt() function demonstrates the difference in syntax. Inspired by Stack Overflows Djack but amended to suit a custom function, rlang::quo_get_expr() with [[]] allows for referencing additional columns.\n\ncreate_plot_alt &lt;- function(df, text, alt_text){\n \n text &lt;- enquo(text)\n alt_text &lt;- enquo(alt_text)\n \n plot_ly(\n  data = df,\n  x = ~x, \n  y = ~y, \n  width = 300, \n  height = 300,\n  type = \"scatter\",\n  mode = \"text+marker\",\n  text = text,\n  textfont = list(size = 50, color = \"#57a2a4\"),\n  hovertemplate = df[[rlang::quo_get_expr(alt_text)]] \n  )\n \n}\n\nIt works!. The first plot with red text - on hover will show ‚Äútext‚Äù, whilst the second plot with blue text shows ‚Äúalt_text‚Äù\n\n# To remove elements not needed\nvoid &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE\n)\n\np1 &lt;- create_plot(df = df, text = text) %&gt;% \n layout(xaxis = void, yaxis = void)\n\np_alt &lt;- create_plot_alt(df = df, text = text, alt_text = alt_text) %&gt;% \n layout(xaxis = void, yaxis = void)\n\n# same hover text as text plotted\n style(p1, showlegend = FALSE)\n\n\n\n\n# alternative hover text\n style(p_alt, showlegend = FALSE)"
  },
  {
    "objectID": "posts/2025-02-06-plotly-hover-var/index.html#acknowledgements",
    "href": "posts/2025-02-06-plotly-hover-var/index.html#acknowledgements",
    "title": "Alternative Hover Text In Custom Function with plotly",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nr-bloggers.com for the reach, platform, and content\nPackages and package maintainer(s):\n\nplotly | Carson Sievert\nrlang | Lionel Henry"
  },
  {
    "objectID": "posts/2024-10-22-slider_rolling_label/index.html",
    "href": "posts/2024-10-22-slider_rolling_label/index.html",
    "title": "Rolling 5-year Sum Label Using slider",
    "section": "",
    "text": "First blog post off the back of an issue at work which required desktop research to figure out. This content aims to better cement my learning and to share to anyone who has been afflicted with a similar issue.\nFor context, I was unable to download new packages and only had the slider package available. Notable packages which came up in research are zoo and TTR which could provide similar results I‚Äôm sure, but the focus here is on slider.\nWhilst calculating a rolling sum took a little while to figure out, the greater block was generating a label for plotting.\nLet‚Äôs begin with setting global options and getting data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(slider)\n\ntheme_set(theme_minimal(\n base_family = 'serif', base_size = 12))\n\nset.seed(4321)\n\n# Get data\nexample_df &lt;- bind_rows(\n tibble(group = \"group_1\",\n  year = c(1991:1993, 1995, 2000:2005),\n  to_add = sample(1:40, 10)),\n \n tibble(group = \"group_2\",\n  year = c(2000:2005),\n  to_add = sample(1:40, 6)))"
  },
  {
    "objectID": "posts/2024-10-22-slider_rolling_label/index.html#problem",
    "href": "posts/2024-10-22-slider_rolling_label/index.html#problem",
    "title": "Rolling 5-year Sum Label Using slider",
    "section": "",
    "text": "First blog post off the back of an issue at work which required desktop research to figure out. This content aims to better cement my learning and to share to anyone who has been afflicted with a similar issue.\nFor context, I was unable to download new packages and only had the slider package available. Notable packages which came up in research are zoo and TTR which could provide similar results I‚Äôm sure, but the focus here is on slider.\nWhilst calculating a rolling sum took a little while to figure out, the greater block was generating a label for plotting.\nLet‚Äôs begin with setting global options and getting data.\n\n# Load packages\nlibrary(tidyverse)\nlibrary(slider)\n\ntheme_set(theme_minimal(\n base_family = 'serif', base_size = 12))\n\nset.seed(4321)\n\n# Get data\nexample_df &lt;- bind_rows(\n tibble(group = \"group_1\",\n  year = c(1991:1993, 1995, 2000:2005),\n  to_add = sample(1:40, 10)),\n \n tibble(group = \"group_2\",\n  year = c(2000:2005),\n  to_add = sample(1:40, 6)))"
  },
  {
    "objectID": "posts/2024-10-22-slider_rolling_label/index.html#calculate-rolling-sum",
    "href": "posts/2024-10-22-slider_rolling_label/index.html#calculate-rolling-sum",
    "title": "Rolling 5-year Sum Label Using slider",
    "section": "Calculate Rolling Sum",
    "text": "Calculate Rolling Sum\nCalculate the rolling sum using an reference column or index, in this instance year. Set before argument to 4 which will then include the value itself to provide a rolling 5 year window. This code is using the _int variant of the slide_index_* functions for integer but there are equivalents for double, logical, character, and data frame.\nIn the function(s) slide_index_* you can‚Äôt reference the column that‚Äôs being iterated on. Instead I used the slide function to generate labels for plotting.\n\nexample_df %&gt;%\n group_by(group) %&gt;% \n arrange(year) %&gt;%\n mutate(\n  # Calculate rolling sum\n  rolling_5_years = slide_index_int(to_add, year, sum, .before = 4),\n  # Generate rolling sum labels\n  rolling_5_years_label = slide(year, ~.x, .before = 4) %&gt;%\n   as.character() %&gt;%\n   unlist()\n ) %&gt;% \n head(5)\n\n# A tibble: 5 √ó 5\n# Groups:   group [1]\n  group    year to_add rolling_5_years rolling_5_years_label          \n  &lt;chr&gt;   &lt;dbl&gt;  &lt;int&gt;           &lt;int&gt; &lt;chr&gt;                          \n1 group_1  1991     27              27 1991                           \n2 group_1  1992     29              56 c(1991, 1992)                  \n3 group_1  1993     10              66 c(1991, 1992, 1993)            \n4 group_1  1995     15              81 c(1991, 1992, 1993, 1995)      \n5 group_1  2000     24              24 c(1991, 1992, 1993, 1995, 2000)\n\n\nNote that this function helpfully counts missing values within the sequence. See above example, 1994 is missing but for 1995 the rolling years sum of 65 includes only 1991, 1992, 1993, and 1995 to_add values.\nNow to visualise!"
  },
  {
    "objectID": "posts/2024-10-22-slider_rolling_label/index.html#visualise",
    "href": "posts/2024-10-22-slider_rolling_label/index.html#visualise",
    "title": "Rolling 5-year Sum Label Using slider",
    "section": "Visualise",
    "text": "Visualise\nImportant to note when using slide to make a label, when the groups starting index value mismatch you will get the below plot which does look messy.\n\nexample_df %&gt;%\n group_by(group) %&gt;% \n arrange(year) %&gt;%\n mutate(\n  # Calculate rolling sum\n  rolling_5_years = slide_index_int(to_add, year, sum, .before = 4),\n  # Generate rolling sum labels\n  rolling_5_years_label = slide(year, ~.x, .before = 4) %&gt;%\n   as.character() %&gt;%\n   unlist()\n ) %&gt;% \n ggplot(aes(x = rolling_5_years, \n            y = rolling_5_years_label, \n            fill = group)) +\n geom_col(position = \"dodge\", colour = \"white\") +\n labs(title = \"Rolling 5 year period example\",\n      subtitle = \"A little messy\", \n      x = \"\", y = \"\") +\n scale_fill_viridis_d(alpha = 0.75, name = \"\") +\n theme(\n  legend.position = \"top\",\n  plot.title.position = \"plot\"\n ) \n\n\n\n\n\n\n\n\nYou may be required to include mismatched starting index values for your use case. But if that‚Äôs not the case and you want to provide a bit more clarity to the plot - I‚Äôve filtered to exclude any year before 2000, now both groups start at the same year / the same starting index value.\nNot all rolling years have the same number of years unless you add the .complete = TRUE argument. Be sure to filter out NA‚Äôs afterwards.\nI‚Äôve coded the labels to collapse years into colon format to maximise plot space.\n\n# Set base rolling value the same\nexample_rolling_sum &lt;- example_df %&gt;%\n filter(!year &lt; 2000) %&gt;% \n group_by(group) %&gt;% \n arrange(year) %&gt;%\n mutate(\n  # Calculate rolling sum\n  rolling_5_years = slide_index_int(to_add, year, sum, .before = 4, .complete = TRUE),\n  # Generate rolling sum labels\n  rolling_5_years_label = slide(as.double(year), ~.x, .before = 4, .complete = TRUE) %&gt;%\n   map(~paste(min(.), \":\", max(.))) %&gt;% \n   unlist()\n )\n\nWarning: There were 16 warnings in `mutate()`.\nThe first warning was:\n‚Ñπ In argument: `rolling_5_years_label = `%&gt;%`(...)`.\n‚Ñπ In group 1: `group = \"group_1\"`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\n‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 15 remaining warnings.\n\n # Plot\n example_rolling_sum %&gt;% \n filter(!is.na(rolling_5_years)) %&gt;% \n ggplot(aes(x = rolling_5_years, \n            y = rolling_5_years_label, \n            fill = group)) +\n geom_col(position = \"dodge\", colour = \"white\") +\n  labs(title = \"Rolling 5 year period example\", \n       subtitle = \"Pretty\",\n       x = \"\", y = \"\") +\n scale_fill_viridis_d(alpha = 0.75, name = \"\") +\n theme(\n  legend.position = \"top\",\n  plot.title.position = \"plot\"\n )"
  },
  {
    "objectID": "posts/2024-10-22-slider_rolling_label/index.html#acknowledgements",
    "href": "posts/2024-10-22-slider_rolling_label/index.html#acknowledgements",
    "title": "Rolling 5-year Sum Label Using slider",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nr-bloggers.com for the reach, platform, and content\nPackages and package maintainer(s):\n\nslider | Davis Vaughan\ntidyverse | Hadley Wickham"
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html",
    "href": "posts/2025-01-28-advent-dash/index.html",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "",
    "text": "For a bit of festive fun üéÑ, I built a flexdashboard from Fortnum & Mason‚Äôs advert calendar ratings. Participants included:\n\nSofia Costa, resident wordsmith\nLaura da Costa Williams, resident chef, with green fingers\nSkye da Costa Williams, resident witch, with crotchet hooks\nMe, resident R-nerd\n\nFortnum & Mason was established in 1707, during that time it has been known for many things, including specialising in tin goods and becoming a post office. Today it‚Äôs known for afternoon tea and food hampers. Their 2024 advent calendar for two consisted of two biscuits and two accompanying teas per day."
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html#project-introduction",
    "href": "posts/2025-01-28-advent-dash/index.html#project-introduction",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "",
    "text": "For a bit of festive fun üéÑ, I built a flexdashboard from Fortnum & Mason‚Äôs advert calendar ratings. Participants included:\n\nSofia Costa, resident wordsmith\nLaura da Costa Williams, resident chef, with green fingers\nSkye da Costa Williams, resident witch, with crotchet hooks\nMe, resident R-nerd\n\nFortnum & Mason was established in 1707, during that time it has been known for many things, including specialising in tin goods and becoming a post office. Today it‚Äôs known for afternoon tea and food hampers. Their 2024 advent calendar for two consisted of two biscuits and two accompanying teas per day."
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html#data",
    "href": "posts/2025-01-28-advent-dash/index.html#data",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "Data",
    "text": "Data\nWe all rated the biscuit, tea, and the pairing out of 10, recording our results in a dependable spreadsheet. After which I ingested and after a few steps created a flexdashboard. You can check these steps in this repo.\nAn idea of the data"
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html#dashboard",
    "href": "posts/2025-01-28-advent-dash/index.html#dashboard",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "Dashboard",
    "text": "Dashboard\nA few navigation notes:\n\nThere are three tabs at the top: Tea, Biscuit, and Pairing\nEach tab has:\n\n3 static value boxes: Best name, Best score, Average score\nAn interactive line chart with hover functionality and click / doubleclick legend values\nAn interactive bar chart, best used by hovering over a row and comparing values. The lower the value the closer that person scored. This was used to determine who had similar taste buds.\n\n\n\nHere is the Advent Dashboard"
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html#notes",
    "href": "posts/2025-01-28-advent-dash/index.html#notes",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "Notes",
    "text": "Notes\nThere was an issue of same scoring Tea, Biscuit, or pairing. The flexdashboard would push all other boxes out to accommodate multiple values. Luckily, in the end there was non.\nIt was a kind-of rush job, I wanted to show the dashboard close to finishing the advent calendars.\nI showed the dashboard to all participants, were they interested? Well for 10 minutes until Christmas dinner was mentioned. Who can blame them ü§§."
  },
  {
    "objectID": "posts/2025-01-28-advent-dash/index.html#acknowledgements",
    "href": "posts/2025-01-28-advent-dash/index.html#acknowledgements",
    "title": "Advent Calendar Ratings Dashboard",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nParticipants for going along with this!\nr-bloggers.com for the reach, platform, and content\nPackages and package maintainer(s):\n\njanitor | Sam Firke\ntidyverse | Hadley Wickham\nplotly | Carson Sievert\nDT | Joe Cheng"
  },
  {
    "objectID": "posts/2025-04-25-char-date-lazy/index.html",
    "href": "posts/2025-04-25-char-date-lazy/index.html",
    "title": "Character to Date conversion using lazy queries",
    "section": "",
    "text": "How to convert a string with format DDMMYYYY, to a date type using lazy queries. The problem is that base r function as.Date() does not have a translatable SQL equivalent. More information on this is detailed in this sql translation article.\nThis problem is largely addressed in the special forms article. However, no example is given for converting a character to a date data type. This post will provide this example.\nLike most of my self described ‚Äúself-tech-support‚Äù post categories, it was introduced through work. Took me a while to come to the answer so here is to saving someone sometime somewhere.\nLet‚Äôs begin with simulating a lazy connection.\n\n# Load packages\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DT)\n\n# Create a local lazy tibble with Postgres SQL connection\ntest_tbl &lt;- lazy_frame(char_date = c(\"01012020\", \"01022020\", \"01032020\"),\n                       con = simulate_postgres())\n\ntest_tbl\n\n&lt;SQL&gt;\nSELECT *\nFROM `df`"
  },
  {
    "objectID": "posts/2025-04-25-char-date-lazy/index.html#problem",
    "href": "posts/2025-04-25-char-date-lazy/index.html#problem",
    "title": "Character to Date conversion using lazy queries",
    "section": "",
    "text": "How to convert a string with format DDMMYYYY, to a date type using lazy queries. The problem is that base r function as.Date() does not have a translatable SQL equivalent. More information on this is detailed in this sql translation article.\nThis problem is largely addressed in the special forms article. However, no example is given for converting a character to a date data type. This post will provide this example.\nLike most of my self described ‚Äúself-tech-support‚Äù post categories, it was introduced through work. Took me a while to come to the answer so here is to saving someone sometime somewhere.\nLet‚Äôs begin with simulating a lazy connection.\n\n# Load packages\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DT)\n\n# Create a local lazy tibble with Postgres SQL connection\ntest_tbl &lt;- lazy_frame(char_date = c(\"01012020\", \"01022020\", \"01032020\"),\n                       con = simulate_postgres())\n\ntest_tbl\n\n&lt;SQL&gt;\nSELECT *\nFROM `df`"
  },
  {
    "objectID": "posts/2025-04-25-char-date-lazy/index.html#acknowledgements",
    "href": "posts/2025-04-25-char-date-lazy/index.html#acknowledgements",
    "title": "Character to Date conversion using lazy queries",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nr-bloggers.com for the reach, platform, and content\nDB Fiddle for SQL sandpit\nPackages and package maintainer(s):\n\ndplyr | Hadley Wickham\ndbplyr | Hadley Wickham\nDT | Joe Cheng"
  },
  {
    "objectID": "about.html#grand-you-made-it-greetings",
    "href": "about.html#grand-you-made-it-greetings",
    "title": "About",
    "section": "",
    "text": "I‚Äôm a data scientist.\nCoding prerequisites include a big screen to not burden my failing eyes too much. A challenge to break the monotony. One cup of black coffee, hold the sugar and milk.\nOften background music without lyrics otherwise I‚Äôll just sing along e.g.¬†Chillhop or DnB. 1-3 chinwags to decompress. A healthy portion of food with all the trimmings.\nBeyond coding: I lay my hat in London, UK, and share the utilities with my son and fianc√©. I‚Äôm a fan of both basketball üèÄ and ‚öΩ football. Love a good read, mainly fantasy. Favourite books are The Gentlemen Bastard & Mistborn Series, follow me on Storygraph, username kurtisasha.\nI like to game. I fell hard for Final Fantasy 8 back in the 90‚Äôs and if limited to one dish for the rest of my life, it‚Äôll be üçï pizza."
  }
]